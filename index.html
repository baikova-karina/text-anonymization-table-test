<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Study Table</title>
  <style>
    body { font-family: Arial, sans-serif; margin: 30px; }
    table {
      width: 100%;
      border-collapse: collapse;
      margin-top: 10px;
    }
    th, td {
      border: 1px solid #ccc;
      padding: 8px;
      text-align: left;
    }
    th {
      background: #f4f4f4;
      cursor: pointer;
      user-select: none;
    }
    th.sorted-asc::after { content: " ▲"; }
    th.sorted-desc::after { content: " ▼"; }
    tr.hide { display: none; }
    input[type="text"] {
      width: 100%;
      padding: 8px;
      font-size: 16px;
      margin-bottom: 8px;
      box-sizing: border-box;
    }
  </style>
</head>
<body>


<h2>Study Results Table</h2>
<input type="text" id="filterInput" placeholder="Type to filter table..." onkeyup="filterTable()">

<table id="resultsTable">
  <thead>
    <tr>
      <th>Study</th>
      <th>Year</th>
      <th>Pre-processing</th>
      <th>Main Method</th>
      <th>Post-processing</th>
      <th>Language</th>
      <th>Training Corpora</th>
      <th>Test Corpora</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="https://aclanthology.org/2023.eacl-demo.22">Ribeiro et al. (2023)</a></td>
      <td>2023</td>
      <td>Tokenization, POS tagging</td>
      <td>CRF-based NER</td>
      <td>Presidio anonymizer (entity replacement)</td>
      <td>English</td>
      <td>i2b2 2006+2014 train sets</td>
      <td>i2b2 2006, i2b2 2014, MIMIC III</td>
      <td>0.948 (i2b2 2006), 0.878 (i2b2 2014), 0.691 (MIMIC)</td>
    </tr>
    <tr>
      <td><a href="https://aclanthology.org/2023.eacl-demo.22">Ribeiro et al. (2023)</a></td>
      <td>2023</td>
      <td>Tokenization</td>
      <td>Presidio+SpaCy NER</td>
      <td>Presidio anonymizer (entity replacement)</td>
      <td>English</td>
      <td>SpaCy model (OntoNotes 5, general domain)</td>
      <td>i2b2 2006, i2b2 2014, MIMIC III</td>
      <td>0.730 (i2b2 2006), 0.646 (i2b2 2014), 0.666 (MIMIC)</td>
    </tr>
    <tr>
      <td><a href="https://aclanthology.org/2023.emnlp-main.224">Liu et al. (2023)</a></td>
      <td>2023</td>
      <td>Tokenization</td>
      <td>CNN</td>
      <td>Optional CRF layer</td>
      <td>Chinese</td>
      <td>HM dataset (300 EMRs)</td>
      <td>HM test set, SY test set, CCKS test set</td>
      <td>HM: 0.982; SY: 0.734; CCKS: 0.524</td>
    </tr>
    <tr>
      <td><a href="https://aclanthology.org/2023.emnlp-main.224">Liu et al. (2023)</a></td>
      <td>2023</td>
      <td>Tokenization, HM-Word2Vec embeddings</td>
      <td>CNN + HM-Word2Vec</td>
      <td>Optional CRF layer</td>
      <td>Chinese</td>
      <td>HM dataset (300 EMRs)</td>
      <td>HM test set, SY test set, CCKS test set</td>
      <td>HM: 0.980; SY: 0.787; CCKS: 0.522</td>
    </tr>
    <tr>
      <td><a href="https://aclanthology.org/2023.emnlp-main.224">Liu et al. (2023)</a></td>
      <td>2023</td>
      <td>Tokenization</td>
      <td>BiLSTM</td>
      <td>Optional CRF layer</td>
      <td>Chinese</td>
      <td>HM dataset (300 EMRs)</td>
      <td>HM test set, SY test set, CCKS test set</td>
      <td>HM: 0.986; SY: 0.789; CCKS: 0.528</td>
    </tr>
    <tr>
      <td><a href="https://aclanthology.org/2023.emnlp-main.224">Liu et al. (2023)</a></td>
      <td>2023</td>
      <td>Tokenization, HM-Word2Vec embeddings</td>
      <td>BiLSTM + HM-Word2Vec</td>
      <td>Optional CRF layer</td>
      <td>Chinese</td>
      <td>HM dataset (300 EMRs)</td>
      <td>HM test set, SY test set, CCKS test set</td>
      <td>HM: 0.989; SY: 0.826; CCKS: 0.483</td>
    </tr>
    <tr>
      <td><a href="https://aclanthology.org/2023.emnlp-main.224">Liu et al. (2023)</a></td>
      <td>2023</td>
      <td>Tokenization</td>
      <td>BERT-wwm</td>
      <td>Optional BiLSTM/CRF layer</td>
      <td>Chinese</td>
      <td>HM dataset (300 EMRs)</td>
      <td>HM test set, SY test set, CCKS test set</td>
      <td>HM: 0.994; SY: 0.970; CCKS: 0.767</td>
    </tr>
    <tr>
      <td><a href="https://aclanthology.org/2023.emnlp-main.224">Liu et al. (2023)</a></td>
      <td>2023</td>
      <td>Tokenization</td>
      <td>MC-BERT</td>
      <td>Optional BiLSTM/CRF layer</td>
      <td>Chinese</td>
      <td>HM dataset (300 EMRs)</td>
      <td>HM test set, SY test set, CCKS test set</td>
      <td>HM: 0.995; SY: 0.970; CCKS: 0.767</td>
    </tr>
    <tr>
      <td><a href="https://aclanthology.org/2023.emnlp-main.224">Liu et al. (2023)</a></td>
      <td>2023</td>
      <td>Tokenization, domain-specific pretraining</td>
      <td>HM-BERT</td>
      <td>Optional BiLSTM/CRF layer</td>
      <td>Chinese</td>
      <td>HM dataset (300 EMRs)</td>
      <td>HM test set, SY test set, CCKS test set</td>
      <td>HM: 0.997; SY: 0.967; CCKS: 0.785</td>
    </tr>
    <tr>
      <td><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10785939/">Lamproudis et al. (2024)</a></td>
      <td>2024</td>
      <td>Tokenization</td>
      <td>ScandiBERT</td>
      <td>None</td>
      <td>Norwegian</td>
      <td>Pseudonymized Stockholm EPR PHI Corpus</td>
      <td>Norwegian synthetic data</td>
      <td>0.64 (macro) / 0.55 (micro)</td>
    </tr>
    <tr>
      <td><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10785939/">Lamproudis et al. (2024)</a></td>
      <td>2024</td>
      <td>Tokenization</td>
      <td>SweDeClin-BERT</td>
      <td>None</td>
      <td>Norwegian</td>
      <td>Pseudonymized Stockholm EPR PHI Corpus</td>
      <td>Norwegian synthetic data</td>
      <td>0.41 (macro) / 0.39 (micro)</td>
    </tr>
    <tr>
      <td><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10785939/">Lamproudis et al. (2024)</a></td>
      <td>2024</td>
      <td>Tokenization</td>
      <td>NorBERT</td>
      <td>None</td>
      <td>Norwegian</td>
      <td>Pseudonymized Stockholm EPR PHI Corpus</td>
      <td>Norwegian synthetic data</td>
      <td>0.62 (macro) / 0.57 (micro)</td>
    </tr>
    <tr>
      <td><a href="https://aclanthology.org/2023.arabicnlp-1.4">Kocaman et al. (2023)</a></td>
      <td>2023</td>
      <td>Tokenization, sentence splitting, GLoVe embeddings</td>
      <td>Bi-LSTM-CNN-Char NER</td>
      <td>Contextual Parser (regex rules), chunk merger, masking/obfuscation</td>
      <td>Arabic</td>
      <td>Translated i2b2 2014 (generic entities)</td>
      <td>Translated i2b2 2014 (generic entities, 20%)</td>
      <td>0.9378 (macro), 0.9572 (micro)</td>
    </tr>
    <tr>
      <td><a href="https://aclanthology.org/2023.arabicnlp-1.4">Kocaman et al. (2023)</a></td>
      <td>2023</td>
      <td>Tokenization, sentence splitting, AraBERT embeddings</td>
      <td>Bi-LSTM-CNN-Char NER</td>
      <td>Contextual Parser (regex rules), chunk merger, masking/obfuscation</td>
      <td>Arabic</td>
      <td>Translated i2b2 2014 (generic entities)</td>
      <td>Translated i2b2 2014 (generic entities, 20%)</td>
      <td>0.9372 (macro), 0.9505 (micro)</td>
    </tr>
    <tr>
      <td><a href="https://aclanthology.org/2023.arabicnlp-1.4">Kocaman et al. (2023)</a></td>
      <td>2023</td>
      <td>Tokenization, sentence splitting, CamelBERT embeddings</td>
      <td>Bi-LSTM-CNN-Char NER</td>
      <td>Contextual Parser (regex rules), chunk merger, masking/obfuscation</td>
      <td>Arabic</td>
      <td>Translated i2b2 2014 (generic entities)</td>
      <td>Translated i2b2 2014 (generic entities, 20%)</td>
      <td>0.9590 (macro), 0.9712 (micro)</td>
    </tr>
    <tr>
      <td><a href="https://aclanthology.org/2023.arabicnlp-1.4">Kocaman et al. (2023)</a></td>
      <td>2023</td>
      <td>Tokenization, sentence splitting</td>
      <td>BERT For Token Classification (AraBERT)</td>
      <td>Contextual Parser (regex rules), chunk merger, masking/obfuscation</td>
      <td>Arabic</td>
      <td>Translated i2b2 2014 (generic entities)</td>
      <td>Translated i2b2 2014 (generic entities, 20%)</td>
      <td>0.9600 (macro), 0.9800 (micro)</td>
    </tr>
    <tr>
      <td><a href="https://aclanthology.org/2023.arabicnlp-1.4">Kocaman et al. (2023)</a></td>
      <td>2023</td>
      <td>Tokenization, sentence splitting</td>
      <td>BERT For Token Classification (CamelBERT)</td>
      <td>Contextual Parser (regex rules), chunk merger, masking/obfuscation</td>
      <td>Arabic</td>
      <td>Translated i2b2 2014 (generic entities)</td>
      <td>Translated i2b2 2014 (generic entities, 20%)</td>
      <td>0.9700 (macro), 0.9800 (micro)</td>
    </tr>
    <tr>
      <td><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC11078567/">Chen et al. (2024)</a></td>
      <td>2024</td>
      <td>Sentence splitting, tokenization (spaCy biomedical model + custom rules)</td>
      <td>RoBERTa (pretrained, fine-tuned on i2b2 2014)</td>
      <td>None reported</td>
      <td>English</td>
      <td>i2b2 2014 discharge summaries</td>
      <td>i2b2 2014 test set</td>
      <td>0.956 (macro, PHI categories), 0.978 (PHI binary)</td>
    </tr>
    <tr>
      <td><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC11078567/">Chen et al. (2024)</a></td>
      <td>2024</td>
      <td>Sentence splitting, tokenization (spaCy biomedical model + custom rules)</td>
      <td>RoBERTa (pretrained, fine-tuned on i2b2 2014)</td>
      <td>None reported</td>
      <td>English</td>
      <td>i2b2 2014 discharge summaries</td>
      <td>Inpatient nursing notes (CONCERN study, 1,334 notes)</td>
      <td>0.887 (macro, PHI categories), 0.932 (PHI binary)</td>
    </tr>
    <tr>
      <td><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC11078567/">Chen et al. (2024)</a></td>
      <td>2024</td>
      <td>Sentence splitting, tokenization (spaCy biomedical model + custom rules)</td>
      <td>ClinicalBERT (pretrained, fine-tuned on i2b2 2014)</td>
      <td>None reported</td>
      <td>English</td>
      <td>i2b2 2014 discharge summaries</td>
      <td>i2b2 2014 test set</td>
      <td>0.820 (macro, PHI categories), 0.963 (PHI binary)</td>
    </tr>
    <tr>
      <td><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC11078567/">Chen et al. (2024)</a></td>
      <td>2024</td>
      <td>Sentence splitting, tokenization (spaCy biomedical model + custom rules)</td>
      <td>ClinicalBERT (pretrained, fine-tuned on i2b2 2014)</td>
      <td>None reported</td>
      <td>English</td>
      <td>i2b2 2014 discharge summaries</td>
      <td>Inpatient nursing notes (CONCERN study, 1,334 notes)</td>
      <td>0.615 (macro, PHI categories), 0.834 (PHI binary)</td>
    </tr>
    <tr>
      <td><a href="https://link.springer.com/article/10.1186/s12911-024-02422-5">Azzouzi et al. (2024)</a></td>
      <td>2024</td>
      <td>HTML parsing, sentence splitting (NLTK), tokenization, BIO tagging, dictionary/rule-based entity marking, normalization, data augmentation</td>
      <td>BiLSTM-CRF + FastText + Flair (stacked)</td>
      <td>Masking / obfuscation of PII in original HTML, entity-level evaluation</td>
      <td>French</td>
      <td>eHOP Clinical Data Warehouse (Rennes University Hospital), automatic annotation using knowledge bases (BAN, Health Directory)</td>
      <td>Manually annotated subset of eHOP CDW (1000 documents, stratified by format)</td>
      <td>0.9713 (macro-avg), 0.9696 (micro-avg)</td>
    </tr>
    <tr>
      <td><a href="https://www.i-jmr.org/2023/1/e46322">Liu et al. (2023)</a></td>
      <td>2023</td>
      <td>Text import, manual annotation, project/data set organization, PII type configuration, autosave, preannotation, iterative retraining</td>
      <td>BiLSTM-CRF (RoBERTa embeddings, implemented in FLAIR)</td>
      <td>Tagging and masking of PII, export of deidentified text, entity-level evaluation</td>
      <td>English</td>
      <td>2014 i2b2 annotated free-text clinical notes</td>
      <td>2014 i2b2 held-out set</td>
      <td>0.9627 (strict entity-level, micro-avg)</td>
    </tr>
    <tr>
      <td><a href="https://www.i-jmr.org/2023/1/e46322">Liu et al. (2023)</a></td>
      <td>2023</td>
      <td>Text import, manual annotation, project/data set organization, PII type configuration, autosave, preannotation, iterative retraining</td>
      <td>BiLSTM-CRF (RoBERTa embeddings, implemented in FLAIR)</td>
      <td>Tagging and masking of PII, export of deidentified text, entity-level evaluation</td>
      <td>English</td>
      <td>600 annotated clinical notes from CardiacAI (Australian hospital)</td>
      <td>Held-out set from CardiacAI</td>
      <td>0.9507 (strict entity-level, micro-avg)</td>
    </tr>
    <tr>
      <td><a href="https://ieeexplore.ieee.org/abstract/document/10321968">Suvirat et al. 2023</a></td>
      <td>2023</td>
      <td>WordPiece tokenization, fine-tuning</td>
      <td>Multilingual BERT</td>
      <td>Classification head (13 outputs)</td>
      <td>Thai</td>
      <td>Thai clinical notes from Songklanagarind Hospital</td>
      <td>Thai clinical notes from Songklanagarind Hospital (held out set)</td>
      <td>0.9262</td>
    </tr>
    <tr>
      <td><a href="https://ieeexplore.ieee.org/abstract/document/10321968">Suvirat et al. 2023</a></td>
      <td>2023</td>
      <td>SentencePiece tokenization, fine-tuning</td>
      <td>WangChan-BERTa</td>
      <td>Classification head (13 outputs)</td>
      <td>Thai</td>
      <td>Thai clinical notes from Songklanagarind Hospital</td>
      <td>Thai clinical notes from Songklanagarind Hospital (held out set)</td>
      <td>0.9338</td>
    </tr>
    <tr>
      <td><a href="https://ieeexplore.ieee.org/abstract/document/10321968">Suvirat et al. 2023</a></td>
      <td>2023</td>
      <td>Byte-pair encoding (BPE) tokenization, fine-tuning</td>
      <td>MEDPSU-RoBERTa</td>
      <td>Classification head (13 outputs)</td>
      <td>Thai</td>
      <td>Thai clinical notes from Songklanagarind Hospital</td>
      <td>Thai clinical notes from Songklanagarind Hospital (held out set)</td>
      <td>0.9552</td>
    </tr>
  </tbody>
</table>

  
<script>
document.addEventListener('DOMContentLoaded', function () {
  const table = document.getElementById("resultsTable");
  const thead = table.tHead;
  const tbody = table.tBodies[0];
  let sortCol = null;
  let sortAsc = true;

  // Add click listeners to all headers
  Array.from(thead.rows[0].cells).forEach((th, colIdx) => {
    th.addEventListener('click', function () {
      // Remove sort indicators from all
      Array.from(thead.rows[0].cells).forEach(th2 => th2.classList.remove('sorted-asc', 'sorted-desc'));
      // Toggle direction
      if (sortCol === colIdx) {
        sortAsc = !sortAsc;
      } else {
        sortCol = colIdx;
        sortAsc = true;
      }
      th.classList.add(sortAsc ? 'sorted-asc' : 'sorted-desc');

      // Sort rows
      const rows = Array.from(tbody.rows);
      rows.sort((a, b) => {
        let aText, bText;
        // Study column: sort by link text
        if (colIdx === 0) {
          aText = a.cells[0].querySelector('a')?.innerText.trim() || a.cells[0].textContent.trim();
          bText = b.cells[0].querySelector('a')?.innerText.trim() || b.cells[0].textContent.trim();
        }
        // Year column: numeric sort
        else if (colIdx === 1) {
          aText = parseInt(a.cells[1].textContent.trim()) || 0;
          bText = parseInt(b.cells[1].textContent.trim()) || 0;
        }
        // F1 column: sort by first number found
        else if (colIdx === 8) {
          const getFirstNumber = str => {
            const m = str.match(/[\d.]+/);
            return m ? parseFloat(m[0]) : 0;
          };
          aText = getFirstNumber(a.cells[8].textContent);
          bText = getFirstNumber(b.cells[8].textContent);
        }
        // All other columns: text sort
        else {
          aText = a.cells[colIdx].textContent.trim().toLowerCase();
          bText = b.cells[colIdx].textContent.trim().toLowerCase();
        }
        if (aText < bText) return sortAsc ? -1 : 1;
        if (aText > bText) return sortAsc ? 1 : -1;
        return 0;
      });
      rows.forEach(row => tbody.appendChild(row));
    });
  });
});
</script>

</body>
</html>
